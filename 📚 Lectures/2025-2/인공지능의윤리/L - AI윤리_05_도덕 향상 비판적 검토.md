# 인공지능을 활용한 도덕 향상에 대한 비판적 검토

> **저자**: 윤준식 (2024)
> **핵심 주제**: AME(인공적 도덕 향상)의 성립 조건과 한계, AEA(인공적 윤리 보조자)의 역할

---

## 📌 핵심 용어 정리

| 용어 | 영문 | 설명 |
|------|------|------|
| **AME** | Artificial Moral Enhancement | 인공적 도덕 향상 |
| **AEA** | Artificial Ethics Assistant | 인공적 윤리 보조자 |
| **BME** | Biomedical Moral Enhancement | 생의학적 도덕 향상 |

**도덕 강화(Moral Enhancement)**: 심리상태에 영향 → 도덕적 행위 유도

| 구분 | 작용 방식 | 측면 |
|------|----------|------|
| **BME** | 생의학적/정신적 개입 | 정의적 측면 (하고 싶어지게) |
| **AME** | AI를 통한 개입 | 인지적 측면 (도덕적 민감성, 순간의 판단 근거) |

---

## 📖 본문 정리

### 1. 서론

**AME의 등장 배경**:
- BME에 제기되는 문제 회피
- 기술적 도덕 향상의 긍정적 평가를 위한 대안

**논문의 목적**: AME의 비판적 검토 (칸트적 비판 - 논의 대상의 성립 조건과 범위, 한계 규명)

**전제**:
- AEA는 기능적 행위성은 있음
- 쾌고감수, 의식, 자의식 없음
- 도덕적 피동자로 대우 ❌

---

### 2. AME의 유형

#### 1) 정보 제공형 - '보조적 향상'

가장 적극적인 유형. 인간의 판단 대신 결정하지 않고 **돕는 것**에 초점

**하위 유형**:
| 유형 | 역할 |
|------|------|
| 도덕 환경 감시자 | 도덕 판단/결정/실천에 대한 정보 제공 |
| 도덕 조직자 | 도덕 목표 설정 + 충족 도움 |
| 도덕 촉진자 | 중립에서 도덕적 반성 심화 |
| 도덕 조언자 | 사전 설정 가치/원리로 조언 제공 |

**특징**: 자율성 보존, 실현

#### 2) 소크라테스적 대화형

**배경**: 라라 & 데커스가 정보 제공형의 한계 대안으로 제시

**정보 제공형의 한계**:
- 수동적이기에 사용자의 도덕적 능력 향상 어려움
- 사용자의 설정 가치/원칙에 매몰될 경우 비판적 검토 불가

**소크라테스적 향상**:
- 사용자의 도덕 문제/해결책 제시 → 내재적 문제 제기
- AEA 사용으로 사용자의 가치관 변화 가능성 필요 = 판단/결정/실천의 개선

#### 3) 모듈식 대화형

**배경**: 폴크만과 가브리엘스가 확장

**특징**:
- 다양한 관점을 가진 소크라테스식 향상
- 특정 관점을 가진 모듈들과의 대화로 영향을 받지만 **마지막에는 나만의 윤리관**을 가짐

---

### 3. 윤리적 문제

#### AEA의 도덕성 수준

```
운용적 도덕 → 기능적 도덕 → 완전한 도덕 행위자(인간)
```

#### 주요 윤리적 문제

| 문제 | 설명 |
|------|------|
| **책임 공백** | 파인튜닝된 AI의 잘못을 제조사에게 물을 수 없음 |
| **정보 유출** | 센서 종류에 따라 개인의 민감한 정보 유출 가능성 |

> [!IMPORTANT]
> **교수님 강조**: 강하게 넛지하면 책임공백 발생, 낮은 자율성으로 넛지하면 도덕강화가 잘 되지 않음

#### 입력/출력의 문제

**입력 (정보 수집)**:
- 수동적 수집(사용자 입력 의존) vs 능동적 수집
- 도덕적 문제는 인간이 약해서가 아니라 **도덕적 민감성 부족**으로 발생
- 능동적 수집을 해야 특정 상황에서 민감성을 키울 수 있음

**출력**:
- 사용자의 자율성 존중 및 AEA의 중립성 필요
- 소크라테스형: 중립성 유지
- 모듈형: 다양한 관점이지만 결론을 내지 않음 (중립)

**중립성 유지 이유**: 책임공백 메꾸기

> [!WARNING]
> **완전히 가치 중립적일 수 있을까?** 완전히 가치 중립적이지 못하다는 사실을 인정하고 들어가야 함

---

### 4. 소크라테스적 향상에 대한 관계적 해석

#### 4.1 산모의 고통과 산파의 능동성

**AME vs BME**:
- AME는 BME와 달리 직접 개입하지 않고 **과정에 개입**하며 자율성 보존
- But 진짜 자율성을 보장하냐? 그건 아닐지도

**소크라테스 산파술의 특성**:
- 불쾌한 경험임
- 지혜를 얻는 과정의 **필연적 요소**로 작용
- 경멸당하고 모욕당해도 **수동적이 아니라 능동적으로** 행함

#### 4.2 사용자-AEA의 협력 관계

**보고시안의 관점**:
- 당혹감과 수치심은 소크라테스적 방법론과 무관
- 당사자의 심리적 결과일 뿐

**저자의 반론**:
- 자신의 윤리적, 도덕의 가치 판단 기준이 깨질 경우 과거의 삶을 비판적으로 평가
- **현재의 나의 정체성의 균열**이 생김
- 진실로 도덕적 향상을 추구한다면 이런 삶이 흔들리는 경험을 해야 함

**환자-의사 비유**:
| 환자-의사 관계 | AEA 관계 |
|--------------|---------|
| 중립이 아닌 목적-제한적 자율성 발휘 | 목적-제한적 자율성 필요 |
| 원치 않는 결과/부작용 가능 | 불쾌한 경험 가능 |
| 환자가 이 사실을 인지하고 인정해야 함 | 사용자가 잠재적 해악 인식해야 함 |
| 돌이킬 수 없음 | **중단 가능** |

---

### 5. 무지의 지와 도덕/윤리의 구분

#### 5.1 AEA와 무지의 지

**AEA의 전제**:
- 자신의 삶을 갖지 않음
- 의식, 자의식, 쾌고감수 없음

**결론**:
- 개인적 가치관, 삶의 문제에 대해 자신의 입장을 강하게 제시해서는 안 됨
- 규범, 윤리적 문제에 대해서는 판례, 법 등의 정보를 강하게 제시할 수 있음

#### 5.2 도덕/윤리의 구분과 AEA의 역할

| 개념 | 정의 | AEA의 자율성 |
|------|------|-------------|
| **도덕** | 보편적 올바름, 이해관계 충돌 상황에 적용되는 의무 | **강한 자율성** 발휘 가능 |
| **윤리** | 좋은 삶, 보편화 어려운 개인마다 차이 있는 가치 추구 | **중립적 태도**로 정보 제공 |

**도덕과 윤리가 중첩되는 경우** (e.g., 하인츠 딜레마):
- 수많은 경우의 수에서 가장 도덕/윤리적인 케이스를 안내
- 일정 수준이 넘는 문제인 경우 강제

---

## 🎓 교수님 정리

### 소크라테스적 대화형 사용 시 주의사항

**1) 사용자가 주의해야 할 부분**:
- **불쾌감을 참아내야 함** (출산의 고통을 감내하듯)
  - 앎을 획득하지 못했을 때
  - 앎을 얻는 과정

**2) 개발자가 주의해야 할 부분**:
- 도덕과 윤리를 구분하여 AEA의 자율성 제한
- **아픔이 있음**을 안내해야 함

---

## 💭 나의 생각

### 책임 공백에 대하여

- 책임 공백이 진짜 생길까? → **아닐 것 같음**
- Open source의 경우 라이센스를 열어두는데, 파인튜닝한 것은 한 사람의 잘못
- '개발자'라는 개념이 굉장히 포괄적:
  - 모델을 개발한 사람?
  - 코드를 짠 사람?
  - 프롬프트를 짠 사람?
- 명확한 구분이 필요함

### 기타 질문들

1. AEA의 자율성이 높아질수록 '책임 공백' 문제가 발생한다는 주장의 윤리적 함의?
   - 자아 없음 → 복지 없음 → 책임을 질 수 없음
   - 쾌고감수도 없음

2. 논문의 특징:
   > "좋은 철학 텍스트는 직관적이고 상식적인 것을 날카롭고 섬세하게 풀어냄"

---

## 🔗 관련 개념

- 소크라테스 산파술 (Maieutics)
- 책임 공백 (Responsibility Gap)
- 도덕적 민감성 (Moral Sensitivity)
- 넛지 (Nudge)
