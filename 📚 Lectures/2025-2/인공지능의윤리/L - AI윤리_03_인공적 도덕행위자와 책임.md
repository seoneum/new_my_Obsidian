# 인공적 도덕행위자와 도덕적 책임

> **저자**: 김은희 (2021)
> **핵심 질문**: 인공적 도덕행위자(AMA)에게 어떤 성격의 도덕적 책임을 물을 수 있는가?

---

## 📌 핵심 개념

### 인공적 도덕행위자(AMA)란?
**AMA (Artificial Moral Agent)**: 자기 나름의 추론 과정을 거쳐 도덕적으로 중요한 어떤 결과를 산출하는 인공지능 기계와 같은 행위자

**특징**:
- 설계자가 알고리즘을 장착했지만, 기계학습과 빅데이터를 통해 설계자가 예상할 수 없는 출력을 냄
- **공학적 자율성** 보유
- 환경 내에서 상호작용성, 자율성, 적응가능성을 갖춘 시스템
- 도덕적 선이나 악을 야기할 수 있는 존재

---

## 📖 본문 정리

### 1. 책임(Responsibility)이란?

**규범 영역의 구분**:
| 영역 | 특성 | 제재 |
|------|------|------|
| **도덕** | 보편성 | 도덕적 비난 |
| **법** | 규칙성 | 구속, 벌금 등 |
| **에티켓** | 상대적 | 사회적 비난 |

### 2. AI가 직면하는 세 가지 문제

| 문제 | 설명 | 책임 귀속 대상 |
|------|------|---------------|
| **Many Hands Problem** | 다수의 존재가 특정 결과 발생에 참여 | 개발자들 |
| **Black Box Problem** | 판단의 메커니즘, 이유를 알기 어려움 | AI 개체 |
| **환경에 넘겨진 통제력** | AI의 결정적 행동원인이 환경적 요인이 됨 (Genetic Algorithm) | 주변 환경 |

> [!IMPORTANT]
> 이 세 문제는 전통적인 책임 귀속 방식으로는 AMA에게 책임을 물을 수 없게 만들어 **'책임 공백(Responsibility Gap)'**을 발생시킴

---

### 3. AMA의 도덕과 책임을 논하는 목적

**화용론적 접근**: 개념이 쓰이는 대상, 맥락, 용도에 맞게 개념 변화

#### AMA의 도덕을 논하는 목적
1. 도덕적으로 좋은 결과를 얻고 나쁜 결과를 피하기 위해
2. ~~AI에게 도덕적 지위를 부여하기 위해~~ (거부)

#### AMA의 도덕적 책임을 논하는 목적
1. **원인 개선**: 도덕적 문제 발생 시 원인 찾기
2. **나쁜 상황 개선**: 재발 방지

> **인간의 도덕적 책임과의 차이**:
> - 도덕적 존중의 의미 (자격 보유) ❌
> - 비난의 감정을 표현 ❌
> - 치유책(보상) ❌

---

### 4. 인간 vs AMA의 책임 비교

| 구분 | 인간의 책임 | AMA의 책임 |
|------|------------|-----------|
| **목적** | 존중, 비난 감정 표현, 보상 제공 | 원인 식별, 상황 개선 |
| **성격** | 과거 지향적(회고적), 응보적 | **미래 지향적(전망적)**, **기능적** |
| **특징** | 자유의지, 도덕적 의도 전제 | 의도 없음, 비난 대상 불가 |

---

### 5. AMA에게 요구되는 세 가지 책임

> [!IMPORTANT]
> **교수님 강조**: AMA에게 적합한 책임의 종류

#### 1) 해명책임 (Accountability)
- **정의**: 공적 영향을 끼칠 수 있는 행위자의 행위 근거는 그로 인해 영향을 받는 이들에게 잘 해명될 만한 것이어야 함
- **예시**: 신용평가 AI가 대출 거부 시, 어떤 데이터와 기준을 사용했는지 설명 요구

#### 2) 분산적 책임 (Distributed Responsibility)
- **정의**: 책임을 특정 개인에게만 묻지 않고 관련된 다수 주체에게 나누어 묻는 것
- **종류**: 집단적 책임 → 비분산적 집단 책임, 분산적 집단 책임
- **대비 개념**: 엄격 책임 (의도가 중요)
- **예시**: 자율주행차 사고 시 제조사, 소프트웨어 개발사, 사용자가 책임 분담

#### 3) 기능적 책임 (Functional Responsibility)
- **정의**: 상황을 더 좋게 만드는 기능(목적)을 수행해야 하는 책임
- **핵심**: 원인 규명과 개선을 위한 책임
- **특징**: 인공지능은 도덕적 의도가 없기에 비난의 대상이 될 수 없음
- **예시**: AI 오류 발생 시 비난 대신 알고리즘 수정하여 재발 방지

---

### 6. 세 가지 문제와 책임의 연결

| 문제 | 해결책 (책임 유형) |
|------|------------------|
| Many Hands Problem | **분산적 책임** |
| Black Box Problem | **해명책임** |
| 환경에 넘겨진 통제력 | **기능적 책임** |

---

### 7. 환경 통제력과 기능적 책임

머신러닝 AI는 환경 데이터에 의해 스스로를 변화시키므로 **통제력이 환경으로 넘어가는** 특성이 있음

**재해석**:
- AI가 환경 데이터를 받아들이는 것 ≠ 통제력 상실
- = **상황 개선이라는 기능을 수행하기 위해 환경과 '상호작용'하는 필수적인 과정**

→ 환경 탓이 아니라, 그 환경 입력값을 통해 더 나은 결과를 내놓도록 하는 기능적 책임 부여

---

### 8. AMA가 도덕적 행위자가 되기 위한 조건

**완전한 도덕적 행위자의 조건이 아님**:
- 도덕적 의식 ❌
- 완전한 자율성 ❌

**필요 조건 ('약한 의미의 도덕적 행위자')**:
- 외부 입력과 달리 스스로 행위를 산출할 수 있는 능력 (공학적 자율성)
- 도덕적으로 좋거나 나쁜 결과를 야기할 수 있는 영향력
- **'기능적 도덕(Functional Morality)'** 단계의 행위자

**평가 기준**:
- 내면의 동기나 의도 ❌
- **결과가 도덕적으로 좋은가 나쁜가** (기능적, 결과론적 측면)

---

## 💭 나의 생각

- 내 주장을 한 문장으로 정식화 할 수 있느냐?
- 상대방이 어떠한 주장을 하였을 때 한 문장으로 정식화 할 수 있느냐?

**행위의 정의**:
> 주변 상황 인식 → 인식 정보 고려 → 고려해서 판단 → 판단에 근거해 움직임 = 행위

- **Agent (행위 주체)**: 행위를 할 수 있는 존재
- **Agency (행위 주체성)**: 이러한 것들을 할 수 있는 능력

---

## 🔗 관련 개념

- 전망적(Prospective) 책임 vs 회고적(Retrospective) 책임
- 응보적(Retributive) 책임
- 책임 공백 (Responsibility Gap)
- 기능주의적 접근
